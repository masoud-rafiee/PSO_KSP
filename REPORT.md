PSO Feature Selection Report

I took the PSO code made for the Knapsack problem and changed it to pick the best features from "diabetes.csv" for diabetes classification. It uses k-NN with 5-fold cross-validation to check how good the features are. I tried two ways to start the particles—uniform random and Latin Hypercube Sampling (LHS)—with seeds 0-4. LHS was a bit steadier, giving accuracies between 0.75 and 0.85. I tested tons of settings (N: 10, 20, 30; T: 30, 50, 70; C1/C2: 1.0, 1.5, 2.0; V_max: 5, 10, 15) over 2430 runs and found N=20, T=50, C1=1.5, C2=2.0, V_max=10 with LHS worked best, hitting 0.84 accuracy on average. Features like Glucose and BMI kept popping up, making the classification better. Each run took about 42-53 seconds—LHS was a tad slower but worth it. I’ve got plots showing how accuracy changes with N and initialization.
